
import { DEEPSEEK_API_KEY, OPENAI_API_KEY } from "./utils.ts";

export async function processWithBuddyChatAI(
  message: string,
  context: string | null,
  language: string,
  recentMessages: any[],
  conversationSummary: string,
  activeTrigger: string,
  interactionType: string,
  attachedFiles: any[] = [],
  customSystemPrompt: string = '',
  maxTokens: number = 400,
  personalTouch: any = null
): Promise<string> {
  
  console.log(`ğŸš€ ENHANCED CHAT: Processing with SMART MEMORY (${recentMessages.length}+ trigger) - ${interactionType} (${maxTokens} tokens)`);

  // ENHANCED: Check if we have images attached for Vision
  const hasImages = attachedFiles && attachedFiles.length > 0 && 
    attachedFiles.some(file => file.type && file.type.startsWith('image/'));

  if (hasImages) {
    console.log(`ğŸ” VISION MODE: Processing ${attachedFiles.length} attached files`);
    return await processWithOpenAIVision(message, attachedFiles, language, personalTouch, maxTokens);
  }

  // ENHANCED: Apply FULL personalization from the start
  let personalizedSystemPrompt = buildPersonalizedSystemPrompt(language, personalTouch);
  
  if (customSystemPrompt && customSystemPrompt.trim()) {
    personalizedSystemPrompt += `\n\nAdditional Instructions: ${customSystemPrompt}`;
  }

  console.log("ğŸ¯ APPLYING FULL PERSONALIZATION:", {
    nickname: personalTouch?.nickname || 'none',
    tone: personalTouch?.tone || 'neutral',
    style: personalTouch?.style || 'detailed',
    instruction: personalTouch?.instruction || ''
  });

  console.log("ğŸ¯ FULL PERSONALIZED SYSTEM PROMPT:", personalizedSystemPrompt.substring(0, 100) + "...");

  // ENHANCED: Build conversation context with smart memory
  const messages = [];
  
  messages.push({
    role: "system",
    content: personalizedSystemPrompt
  });

  // ENHANCED: Add conversation context for continuity (SMART MEMORY)
  if (conversationSummary && conversationSummary.trim()) {
    console.log("ğŸ§  SMART MEMORY: Using enhanced conversation context");
    messages.push({
      role: "system",
      content: `Previous conversation context: ${conversationSummary}`
    });
  }

  // ENHANCED: Add recent messages for better context understanding
  if (recentMessages && recentMessages.length > 0) {
    console.log(`ğŸ§  CONTEXT: Using ${recentMessages.length} recent messages for continuity`);
    recentMessages.forEach(msg => {
      if (msg.role && msg.content) {
        messages.push({
          role: msg.role,
          content: msg.content
        });
      }
    });
  }

  // Add current user message
  messages.push({
    role: "user",
    content: message
  });

  console.log(`ğŸ§  MESSAGE COUNT: System(1) + Context(${conversationSummary ? 1 : 0}) + History(${recentMessages.length}) + Current(1) = ${messages.length}`);

  // ENHANCED: Personalized temperature based on tone
  const temperature = personalTouch?.tone === 'serious' ? 0.3 : 
                     personalTouch?.tone === 'casual' ? 0.7 : 0.5;
  console.log(`ğŸ¯ PERSONALIZED TEMPERATURE: ${temperature}`);

  return await makeAPICall(messages, maxTokens, temperature);
}

async function processWithOpenAIVision(
  message: string, 
  attachedFiles: any[], 
  language: string, 
  personalTouch: any, 
  maxTokens: number
): Promise<string> {
  
  console.log("ğŸ” VISION PROCESSING: Starting OpenAI Vision analysis");
  
  if (!OPENAI_API_KEY) {
    return language === 'ar' 
      ? 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±.'
      : 'Sorry, OpenAI API key is not available for image analysis.';
  }

  // Build personalized system prompt for vision
  const personalizedSystemPrompt = buildPersonalizedSystemPrompt(language, personalTouch);

  // Build vision message content
  const messageContent = [
    {
      type: "text",
      text: message || (language === 'ar' ? 'Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©' : 'Analyze this image')
    }
  ];

  // Add images to message content
  attachedFiles.forEach(file => {
    if (file.type && file.type.startsWith('image/')) {
      if (file.optimized && file.publicUrl) {
        // Use optimized URL for Vision
        messageContent.push({
          type: "image_url",
          image_url: {
            url: file.publicUrl,
            detail: "high" // High detail for better analysis
          }
        });
        console.log(`ğŸ” VISION: Added optimized image URL`);
      } else if (file.url) {
        // Fallback to regular URL
        messageContent.push({
          type: "image_url",
          image_url: {
            url: file.url,
            detail: "high"
          }
        });
        console.log(`ğŸ” VISION: Added fallback image URL`);
      }
    }
  });

  const messages = [
    {
      role: "system",
      content: personalizedSystemPrompt
    },
    {
      role: "user",
      content: messageContent
    }
  ];

  try {
    console.log("ğŸ” VISION API: Calling OpenAI Vision with gpt-4o");
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o', // Vision-capable model
        messages: messages,
        max_tokens: Math.min(maxTokens, 1000), // Vision responses can be longer
        temperature: personalTouch?.tone === 'serious' ? 0.3 : 0.5
      }),
    });

    if (!response.ok) {
      console.error("ğŸ” VISION ERROR: API call failed", response.status);
      throw new Error(`OpenAI Vision API error: ${response.status}`);
    }

    const result = await response.json();
    const content = result.choices?.[0]?.message?.content;

    if (!content) {
      throw new Error('No content received from Vision API');
    }

    console.log(`ğŸ” VISION SUCCESS: Generated ${content.length} characters`);
    return content;

  } catch (error) {
    console.error("ğŸ” VISION ERROR:", error);
    
    // Fallback to text-only mode
    const fallbackMessage = language === 'ar' 
      ? `Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø§Ù„Ù†Øµ ÙÙ‚Ø·: ${message}`
      : `Sorry, I couldn't analyze the image. I can help with text only: ${message}`;
    
    return await processTextOnly(fallbackMessage, language, personalTouch, maxTokens);
  }
}

async function processTextOnly(
  message: string, 
  language: string, 
  personalTouch: any, 
  maxTokens: number
): Promise<string> {
  
  const personalizedSystemPrompt = buildPersonalizedSystemPrompt(language, personalTouch);
  
  const messages = [
    {
      role: "system",
      content: personalizedSystemPrompt
    },
    {
      role: "user",
      content: message
    }
  ];

  return await makeAPICall(messages, maxTokens, 0.5);
}

function buildPersonalizedSystemPrompt(language: string, personalTouch: any): string {
  let systemPrompt = language === 'ar' 
    ? "Ø£Ù†Øª ÙˆÙ‚ØªÙŠ AIØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯ ÙˆÙˆØ¯ÙˆØ¯."
    : "You are Wakti AI, a smart, helpful, and friendly assistant.";

  if (personalTouch) {
    // Add nickname
    if (personalTouch.nickname && personalTouch.nickname.trim()) {
      systemPrompt += language === 'ar' 
        ? ` Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠÙØ¶Ù„ Ø£Ù† ØªÙ†Ø§Ø¯ÙŠÙ‡ ${personalTouch.nickname.trim()}.`
        : ` The user prefers to be called ${personalTouch.nickname.trim()}.`;
    }

    // Add tone
    if (personalTouch.tone) {
      switch (personalTouch.tone) {
        case 'serious':
          systemPrompt += language === 'ar' 
            ? " ØªØ­Ø¯Ø« Ø¨Ø¬Ø¯ÙŠØ© ÙˆÙ…Ù‡Ù†ÙŠØ©."
            : " Speak seriously and professionally.";
          break;
        case 'casual':
          systemPrompt += language === 'ar' 
            ? " ØªØ­Ø¯Ø« Ø¨Ø·Ø±ÙŠÙ‚Ø© ØºÙŠØ± Ø±Ø³Ù…ÙŠØ© ÙˆÙˆØ¯ÙŠØ©."
            : " Speak casually and friendly.";
          break;
        case 'humorous':
          systemPrompt += language === 'ar' 
            ? " Ø£Ø¶Ù Ù„Ù…Ø³Ø© Ù…Ù† Ø§Ù„ÙÙƒØ§Ù‡Ø© Ø¥Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ."
            : " Add humor to your responses.";
          break;
      }
    }

    // Add style
    if (personalTouch.style) {
      switch (personalTouch.style) {
        case 'short answers':
          systemPrompt += language === 'ar' 
            ? " ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹."
            : " Be direct and concise.";
          break;
        case 'detailed':
          systemPrompt += language === 'ar' 
            ? " Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙØµÙ„Ø© ÙˆØ´Ø§Ù…Ù„Ø©."
            : " Provide detailed and comprehensive answers.";
          break;
      }
    }

    // Add custom instruction
    if (personalTouch.instruction && personalTouch.instruction.trim()) {
      systemPrompt += ` ${personalTouch.instruction.trim()}`;
    }
  }

  // Add language-specific guidance
  if (language === 'ar') {
    systemPrompt += " Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹.";
  } else {
    systemPrompt += " Always respond in English.";
  }

  return systemPrompt;
}

async function makeAPICall(messages: any[], maxTokens: number, temperature: number): Promise<string> {
  const maxRetries = 3;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    console.log(`ğŸ”„ API Call Attempt ${attempt}/${maxRetries}`);
    
    try {
      // Try OpenAI first if available
      if (OPENAI_API_KEY) {
        console.log("ğŸš€ Trying OpenAI with proper timeout handling...");
        
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 12000); // 12 second timeout
        
        try {
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${OPENAI_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: messages,
              max_tokens: maxTokens,
              temperature: temperature
            }),
            signal: controller.signal
          });
          
          clearTimeout(timeoutId);
          
          if (response.ok) {
            const result = await response.json();
            const content = result.choices?.[0]?.message?.content;
            if (content) {
              console.log("âœ… OpenAI Success");
              console.log(`âœ… SUCCESS via OPENAI: ${content.length} characters (SMART MEMORY ENABLED)`);
              return content;
            }
          }
        } catch (error: any) {
          clearTimeout(timeoutId);
          if (error.name === 'AbortError') {
            console.log("â° OpenAI timeout, trying DeepSeek...");
          } else {
            console.log("âŒ OpenAI failed, trying DeepSeek...");
          }
        }
      }

      // Fallback to DeepSeek
      if (DEEPSEEK_API_KEY) {
        console.log("ğŸš€ Trying DeepSeek as fallback...");
        
        const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${DEEPSEEK_API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'deepseek-chat',
            messages: messages,
            max_tokens: maxTokens,
            temperature: temperature
          })
        });

        if (response.ok) {
          const result = await response.json();
          const content = result.choices?.[0]?.message?.content;
          if (content) {
            console.log("âœ… DeepSeek Success");
            console.log(`âœ… SUCCESS via DEEPSEEK: ${content.length} characters (SMART MEMORY ENABLED)`);
            return content;
          }
        }
      }

      // If we get here, both APIs failed this attempt
      if (attempt === maxRetries) {
        throw new Error("All AI services are currently unavailable");
      }
      
      // Wait before retry
      await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
      
    } catch (error) {
      console.error(`âŒ Attempt ${attempt} failed:`, error);
      if (attempt === maxRetries) {
        throw error;
      }
    }
  }

  throw new Error("Failed to get AI response after all retries");
}
