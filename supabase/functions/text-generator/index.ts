import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { generateGemini } from "../_shared/gemini.ts";
import { logAIFromRequest } from "../_shared/aiLogger.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
};

const DEEPSEEK_API_KEY = Deno.env.get("DEEPSEEK_API_KEY");
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const GEMINI_API_KEY = Deno.env.get("GEMINI_API_KEY") || Deno.env.get("GOOGLE_GENAI_API_KEY");
const ANTHROPIC_API_KEY = Deno.env.get("ANTHROPIC_API_KEY");

// Claude Haiku - cheapest cost-effective Claude model for text generation
const CLAUDE_MODEL = 'claude-3-5-haiku-latest';

// Content type configurations
const contentConfig = {
  // Short form content types (emails, messages, etc.)
  email: { baseTokens: 1024, model: 'gpt-4.1-mini', temperature: 0.7 },
  text_message: { baseTokens: 512, model: 'gpt-4.1-mini', temperature: 0.7 },
  message: { baseTokens: 768, model: 'gpt-4.1-mini', temperature: 0.7 },
  
  // Long form content types
  blog_post: { baseTokens: 2048, model: 'gpt-4.1-mini', temperature: 0.7 },
  story: { baseTokens: 3072, model: 'gpt-4.1-mini', temperature: 0.8 },
  press_release: { baseTokens: 1536, model: 'gpt-4.1-mini', temperature: 0.5 },
  cover_letter: { baseTokens: 1024, model: 'gpt-4.1-mini', temperature: 0.6 },
  research_brief: { baseTokens: 2048, model: 'gpt-4.1-mini', temperature: 0.4 },
  research_report: { baseTokens: 4096, model: 'gpt-4.1-mini', temperature: 0.4 },
  case_study: { baseTokens: 3072, model: 'gpt-4.1-mini', temperature: 0.6 },
  how_to_guide: { baseTokens: 2048, model: 'gpt-4.1-mini', temperature: 0.5 },
  policy_note: { baseTokens: 1536, model: 'gpt-4.1-mini', temperature: 0.4 },
  product_description: { baseTokens: 768, model: 'gpt-4.1-mini', temperature: 0.7 },
  essay: { baseTokens: 3072, model: 'gpt-4.1-mini', temperature: 0.7 },
  proposal: { baseTokens: 2560, model: 'gpt-4.1-mini', temperature: 0.6 },
  official_letter: { baseTokens: 1024, model: 'gpt-4.1-mini', temperature: 0.5 },
  poem: { baseTokens: 1024, model: 'gpt-4.1-mini', temperature: 0.9 },
  
  // Default fallback
  default: { baseTokens: 1024, model: 'gpt-4.1-mini', temperature: 0.7 }
};

// Length multipliers
const lengthMultipliers = {
  'very_short': 0.5,
  'short': 0.75,
  'medium': 1.0,
  'long': 1.5,
  'very_long': 2.0
};

// Tone adjustments
const toneAdjustments = {
  // Creative tones
  funny: { tempAdj: +0.2, tokenAdj: 1.0 },
  romantic: { tempAdj: +0.2, tokenAdj: 1.0 },
  humorous: { tempAdj: +0.3, tokenAdj: 1.0 },
  inspirational: { tempAdj: +0.1, tokenAdj: 1.1 },
  motivational: { tempAdj: +0.1, tokenAdj: 1.1 },
  
  // Professional tones
  professional: { tempAdj: -0.1, tokenAdj: 1.0 },
  formal: { tempAdj: -0.2, tokenAdj: 1.0 },
  serious: { tempAdj: -0.2, tokenAdj: 1.0 },
  authoritative: { tempAdj: -0.1, tokenAdj: 1.0 },
  
  // Neutral tones
  neutral: { tempAdj: 0, tokenAdj: 1.0 },
  friendly: { tempAdj: +0.1, tokenAdj: 1.0 },
  empathetic: { tempAdj: +0.1, tokenAdj: 1.0 },
  
  // Default fallback
  default: { tempAdj: 0, tokenAdj: 1.0 }
};

// Register adjustments: influence temperature and tokens based on register (formality/style)
const registerAdjustments = {
  auto:       { tempAdj: 0.0,  tokenAdj: 1.0 },
  formal:     { tempAdj: -0.10, tokenAdj: 1.0 },
  neutral:    { tempAdj: 0.0,  tokenAdj: 1.0 },
  casual:     { tempAdj: +0.05, tokenAdj: 1.0 },
  slang:      { tempAdj: +0.10, tokenAdj: 0.90 },
  poetic:     { tempAdj: +0.05, tokenAdj: 1.10 },
  gen_z:      { tempAdj: +0.10, tokenAdj: 0.90 },
  business_formal: { tempAdj: -0.10, tokenAdj: 1.0 },
  executive_brief: { tempAdj: -0.10, tokenAdj: 0.85 },
} as const;

// Get generation parameters based on content type, tone, length, and register
function getGenerationParams(contentType: string, tone: string, length: string, register?: string) {
  const config = contentConfig[contentType as keyof typeof contentConfig] || contentConfig.default;
  const lengthMult = lengthMultipliers[length as keyof typeof lengthMultipliers] || 1.0;
  const toneAdj = toneAdjustments[tone as keyof typeof toneAdjustments] || toneAdjustments.default;
  const regAdj = registerAdjustments[(register as keyof typeof registerAdjustments) || 'auto'] || registerAdjustments.auto;
  
  // Calculate final values with bounds
  const finalTemp = Math.min(1.0, Math.max(0.1, config.temperature + toneAdj.tempAdj + regAdj.tempAdj));
  const finalTokens = Math.max(256, Math.min(4096, Math.floor(config.baseTokens * lengthMult * toneAdj.tokenAdj * regAdj.tokenAdj)));
  
  return {
    model: config.model,
    temperature: finalTemp,
    max_tokens: finalTokens
  };
}

serve(async (req) => {
  // Handle CORS
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log("ğŸ¯ Text Generator: Function called successfully - Processing request");
    console.log("ğŸ¯ Text Generator: Request method:", req.method);
    console.log("ğŸ¯ Text Generator: Request headers:", Object.fromEntries(req.headers.entries()));
    
    if (!ANTHROPIC_API_KEY && !OPENAI_API_KEY && !DEEPSEEK_API_KEY) {
      console.error("ğŸš¨ Text Generator: No AI provider keys found in environment");
      return new Response(
        JSON.stringify({ 
          success: false,
          error: "No AI provider configured. Please add ANTHROPIC_API_KEY, OPENAI_API_KEY, or DEEPSEEK_API_KEY to Supabase Edge Function Secrets." 
        }),
        { 
          status: 500, 
          headers: { ...corsHeaders, "Content-Type": "application/json" }
        }
      );
    }

    let requestBody;
    try {
      requestBody = await req.json();
      console.log("ğŸ¯ Text Generator: Request body parsed successfully");
    } catch (parseError) {
      console.error("ğŸ¯ Text Generator: Failed to parse request body:", parseError);
      requestBody = {};
    }

    const { prompt, mode, language, languageVariant, messageAnalysis, modelPreference: _modelPreference, temperature: _temperature, contentType, length, replyLength, tone, register, emojis, image, extractTarget, webSearch } = requestBody;

    console.log("ğŸ¯ Request details:", { 
      promptLength: prompt?.length || 0, 
      mode, 
      language,
      hasMessageAnalysis: !!messageAnalysis,
      contentType,
      length,
      replyLength,
      tone,
      register,
      languageVariant,
      emojis,
      hasImage: !!image,
      extractTarget,
      webSearch: !!webSearch
    });

    // ============================================
    // MODE: extract - Extract text from screenshot
    // ============================================
    if (mode === 'extract' && image) {
      console.log("ğŸ¯ Text Generator: EXTRACT MODE - Processing screenshot");
      
      if (!OPENAI_API_KEY) {
        return new Response(
          JSON.stringify({ 
            success: false,
            error: "OpenAI API key required for image extraction" 
          }),
          { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }

      try {
        // Prepare the image for OpenAI Vision API
        let imageUrl = image;
        if (!image.startsWith('http') && !image.startsWith('data:')) {
          imageUrl = `data:image/jpeg;base64,${image}`;
        }

        // Use structured extraction prompt to detect form fields
        const structuredPrompt = language === 'ar'
          ? `Ø§Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆØ­Ø¯Ø¯ Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±Ø§Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø· (Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆÙ…ØµØ¯Ø±Ù‡)ØŒ Ø«Ù… Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†.

Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø· ÙˆØ¨Ù†ÙØ³ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©. Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§:
- Ù„Ø§ ØªÙØ±Ø¬Ø¹ Ø£ÙŠ Ù†Øµ Ø®Ø§Ø±Ø¬ JSON.
- Ø§Ø¬Ø¹Ù„ rawText Ø´Ø§Ù…Ù„Ø§Ù‹ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù† (Ù„Ø§ ØªØ®ØªØµØ±).
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„Ù‹Ø§ØŒ Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Ù…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø±Ø¤ÙŠØªÙ‡ Ø¨ÙˆØ¶ÙˆØ­.

{
  "isScreenshot": true/false,
  "sourceType": "email" | "whatsapp" | "sms" | "imessage" | "support_portal" | "web_page" | "form" | "handwritten" | "photo" | "other",
  "deviceType": "phone" | "tablet" | "desktop" | "unknown",
  "isForm": true/false,
  "formType": "support_ticket" | "contact_form" | "email" | "message" | "other",
  "fields": {
    "subject": "Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¥Ù† ÙˆØ¬Ø¯",
    "category": "Ø§Ù„ÙØ¦Ø© Ø£Ùˆ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "service_affected": "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "severity": "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„Ø®Ø·ÙˆØ±Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "message": "Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ / ÙˆØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©",
    "sender": "Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„ Ø¥Ù† ÙˆØ¬Ø¯",
    "recipient": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… Ø¥Ù† ÙˆØ¬Ø¯"
  },
  "rawText": "ÙƒÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¦ÙŠ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©"
}

Ø£Ø¹Ø¯ JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ.`
          : `Look at this image carefully and first identify what it is (type + source), then extract as much text as possible.

Return ONLY valid JSON using this exact schema:
- No extra text outside JSON.
- rawText should include as much visible text as possible (do NOT summarize).
- If the text is long, extract everything you can clearly read.

{
  "isScreenshot": true/false,
  "sourceType": "email" | "whatsapp" | "sms" | "imessage" | "support_portal" | "web_page" | "form" | "handwritten" | "photo" | "other",
  "deviceType": "phone" | "tablet" | "desktop" | "unknown",
  "isForm": true/false,
  "formType": "support_ticket" | "contact_form" | "email" | "message" | "other",
  "fields": {
    "subject": "the subject/title if present",
    "category": "category/issue type if present",
    "service_affected": "which service is affected if present",
    "severity": "priority or severity if present",
    "message": "the main message body / issue description",
    "sender": "sender name if present",
    "recipient": "recipient name if present"
  },
  "rawText": "all visible text in the image"
}

Return ONLY the JSON, no additional text.`;

        console.log("ğŸ¯ Text Generator: Calling OpenAI Vision for structured extraction");
        const startVision = Date.now();
        
        const visionResponse = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
          },
          body: JSON.stringify({
            model: "gpt-4o",
            messages: [
              {
                role: "user",
                content: [
                  { type: "text", text: structuredPrompt },
                  { type: "image_url", image_url: { url: imageUrl, detail: "high" } }
                ]
              }
            ],
            response_format: { type: "json_object" },
            max_tokens: 4000,
            temperature: 0.1,
          }),
        });

        const visionDuration = Date.now() - startVision;
        console.log(`ğŸ¯ Text Generator: Vision extraction completed in ${visionDuration}ms, status: ${visionResponse.status}`);

        if (!visionResponse.ok) {
          const errText = await visionResponse.text();
          console.error("ğŸ¯ Text Generator: Vision API error:", errText);
          return new Response(
            JSON.stringify({ success: false, error: "Failed to extract text from image" }),
            { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        }

        const visionResult = await visionResponse.json();
        const rawContent = visionResult.choices?.[0]?.message?.content || "";

        if (!rawContent.trim()) {
          return new Response(
            JSON.stringify({ success: false, error: "No text found in image" }),
            { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        }

        // Try to parse as JSON, fallback to raw text
        let extractedData: {
          isScreenshot?: boolean;
          sourceType?: string;
          deviceType?: string;
          isForm?: boolean;
          formType?: string;
          fields?: Record<string, string>;
          rawText?: string;
        } = {};
        let extractedText = rawContent;

        try {
          // Clean up potential markdown code blocks
          let jsonStr = rawContent.trim();
          if (jsonStr.startsWith('```json')) jsonStr = jsonStr.slice(7);
          if (jsonStr.startsWith('```')) jsonStr = jsonStr.slice(3);
          if (jsonStr.endsWith('```')) jsonStr = jsonStr.slice(0, -3);
          jsonStr = jsonStr.trim();
          
          extractedData = JSON.parse(jsonStr);
          extractedText = extractedData.rawText || rawContent;
          console.log("ğŸ¯ Text Generator: Successfully parsed structured form data:", {
            isForm: extractedData.isForm,
            formType: extractedData.formType,
            fieldsCount: extractedData.fields ? Object.keys(extractedData.fields).length : 0
          });
        } catch (_parseErr) {
          console.log("ğŸ¯ Text Generator: Could not parse as JSON, using raw text");
          extractedData = { isForm: false, rawText: rawContent };
        }

        console.log("ğŸ¯ Text Generator: Successfully extracted, length:", extractedText.length);

        // Log successful extraction
        await logAIFromRequest(req, {
          functionName: "text-generator",
          provider: "openai",
          model: "gpt-4o",
          inputText: "[image extraction]",
          outputText: extractedText,
          durationMs: visionDuration,
          status: "success"
        });

        return new Response(
          JSON.stringify({
            success: true,
            extractedText,
            extractedForm: extractedData.isForm ? {
              formType: extractedData.formType || 'other',
              fields: extractedData.fields || {}
            } : null,
            extractedMeta: {
              isScreenshot: extractedData.isScreenshot ?? true,
              sourceType: extractedData.sourceType || 'other',
              deviceType: extractedData.deviceType || 'unknown',
            },
            mode: 'extract',
            extractTarget,
            modelUsed: 'gpt-4o'
          }),
          { headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );

      } catch (e: unknown) {
        const err = e as Error;
        console.error("ğŸ¯ Text Generator: Extraction error:", err.message);
        return new Response(
          JSON.stringify({ success: false, error: `Extraction failed: ${err.message}` }),
          { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
    }

    // ============================================
    // MODE: compose/reply - Normal text generation
    // ============================================
    if (!prompt) {
      console.error("ğŸ¯ Text Generator: Missing prompt in request");
      return new Response(
        JSON.stringify({ 
          success: false,
          error: "Prompt is required" 
        }),
        { 
          status: 400, 
          headers: { ...corsHeaders, "Content-Type": "application/json" }
        }
      );
    }

    console.log("ğŸ¯ Text Generator: Calling AI provider for text generation");
    console.log("ğŸ¯ Mode:", mode, "| Language:", language, "| Prompt length:", prompt.length);
    console.log("ğŸ¯ Structured fields:", { tone, register, languageVariant, emojis, contentType });

    const systemPrompt = buildSystemPrompt(language, { tone, register, languageVariant, emojis, contentType });
    const genParams = getGenerationParams(contentType, tone, length || replyLength || 'medium', register);
    console.log("ğŸ¯ Generation parameters:", genParams);

    let generatedText: string | undefined;

    // â”€â”€ Web Search: OpenAI gpt-4.1-mini (Responses API) â”€â”€
    if (webSearch && OPENAI_API_KEY) {
      try {
        console.log("ğŸ¯ Text Generator: Web Search enabled - using OpenAI gpt-4.1-mini Responses API");
        const startWebSearch = Date.now();
        
        const webSearchPrompt = language === 'ar'
          ? `Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªØ±Ù. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø¹Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ØªØ§Ù„ÙŠ.

**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:**
1. Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆÙŠØ¨ Ø¹Ù† Ø£Ø­Ø¯Ø« Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
2. Ø£Ø¶Ù ØªÙˆØ§Ø±ÙŠØ® Ù…Ø­Ø¯Ø¯Ø© ÙˆØ£Ø±Ù‚Ø§Ù… Ø¯Ù‚ÙŠÙ‚Ø© (Ù…Ø«Ù„: "ÙÙŠ 2024ØŒ Ø¨Ù„Øº Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ§Ø­ 5.6 Ù…Ù„ÙŠÙˆÙ†")
3. Ø§Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ø£Ù…Ø§ÙƒÙ† ÙˆØ§Ù„Ù…Ù†Ø¸Ù…Ø§Øª ÙˆØ§Ù„Ø£Ø­Ø¯Ø§Ø«
4. Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ù†Ø¸Ù… Ù…Ø¹ ÙÙ‚Ø±Ø§Øª Ù…ØªÙ…Ø§Ø³ÙƒØ©
5. Ù„Ø§ ØªØ­Ø°Ù Ø£ÙŠ Ø´ÙŠØ¡ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… - ÙÙ‚Ø· Ø¹Ø²Ø²Ù‡ Ø¨Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±
6. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙ†ÙŠØ§Ù‹ Ø¨Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆÙ…ÙÙŠØ¯Ø§Ù‹ Ù„Ù„Ù‚Ø§Ø±Ø¦

Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹:
${prompt}`
          : `You are a professional writer. The user wants high-quality content about the following topic.

**Critical Instructions:**
1. Search the web for the LATEST facts, statistics, and real data
2. Include SPECIFIC numbers, dates, and figures (e.g., "In 2024, tourism reached 5.6 million visitors")
3. Mention REAL names of places, organizations, events, and people where relevant
4. Write in a clear, well-organized style with coherent paragraphs
5. Do NOT remove or change the user's original content - only ENHANCE it with facts and sources
6. Make the content information-rich and valuable to the reader
7. If writing an essay or report, include a strong introduction, detailed body paragraphs, and a clear conclusion

Topic:
${prompt}`;

        const responsesApiBody = {
          model: 'gpt-4.1-mini',
          input: webSearchPrompt,
          tools: [{ type: 'web_search' }],
          instructions: systemPrompt,
          temperature: genParams.temperature,
        };

        const webSearchResponse = await fetch("https://api.openai.com/v1/responses", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
          },
          body: JSON.stringify(responsesApiBody),
        });

        const webSearchDuration = Date.now() - startWebSearch;
        console.log(`ğŸ¯ Text Generator: Web Search completed in ${webSearchDuration}ms, status ${webSearchResponse.status}`);

        if (webSearchResponse.ok) {
          const webSearchResult = await webSearchResponse.json();
          const outputText = webSearchResult.output_text || webSearchResult.output?.[0]?.content?.[0]?.text || '';
          
          const sources: Array<{ title: string; url: string }> = [];
          if (Array.isArray(webSearchResult.output)) {
            for (const item of webSearchResult.output) {
              if (item.type === 'web_search_call' && Array.isArray(item.search_results)) {
                for (const result of item.search_results) {
                  if (result.url && result.title) sources.push({ title: result.title, url: result.url });
                }
              }
              if (item.type === 'message' && Array.isArray(item.content)) {
                for (const contentItem of item.content) {
                  if (contentItem.type === 'output_text' && Array.isArray(contentItem.annotations)) {
                    for (const annotation of contentItem.annotations) {
                      if (annotation.type === 'url_citation' && annotation.url && annotation.title) {
                        if (!sources.some(s => s.url === annotation.url)) {
                          sources.push({ title: annotation.title, url: annotation.url });
                        }
                      }
                    }
                  }
                }
              }
            }
          }
          
          if (outputText) {
            generatedText = sanitizeEmDashes(outputText);

            await logAIFromRequest(req, {
              functionName: "text-generator",
              provider: "openai",
              model: "gpt-4.1-mini",
              inputText: prompt,
              outputText: generatedText,
              durationMs: webSearchDuration,
              status: "success"
            });

            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed: 'gpt-4.1-mini (web_search)',
                temperatureUsed: genParams.temperature,
                contentType: contentType || null,
                webSearchUsed: true,
                webSearchSources: sources
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          } else {
            console.warn("ğŸ¯ Text Generator: Web Search returned no content, falling back");
          }
        } else {
          const errTxt = await webSearchResponse.text();
          console.warn("ğŸ¯ Text Generator: Web Search API error, falling back:", { status: webSearchResponse.status, error: errTxt });
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: Web Search threw error, falling back:", e);
      }
    }

    // â”€â”€ Primary: Claude Haiku (non-web-search) â”€â”€
    if (ANTHROPIC_API_KEY && !generatedText) {
      try {
        console.log(`ğŸ¯ Text Generator: PRIMARY - Claude (${CLAUDE_MODEL})`);
        const startClaude = Date.now();
        const claudeResponse = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": ANTHROPIC_API_KEY,
            "anthropic-version": "2023-06-01",
          },
          body: JSON.stringify({
            model: CLAUDE_MODEL,
            system: systemPrompt,
            messages: [
              { role: "user", content: prompt }
            ],
            temperature: genParams.temperature,
            max_tokens: genParams.max_tokens,
          }),
        });
        const claudeDuration = Date.now() - startClaude;
        console.log(`ğŸ¯ Text Generator: Claude completed in ${claudeDuration}ms, status ${claudeResponse.status}`);

        if (claudeResponse.ok) {
          const claudeResult = await claudeResponse.json();
          const content = claudeResult.content?.[0]?.text || "";
          if (content) {
            generatedText = sanitizeEmDashes(content);
            console.log("ğŸ¯ Text Generator: Claude success, length:", generatedText?.length || 0);

            await logAIFromRequest(req, {
              functionName: "text-generator",
              provider: "anthropic",
              model: CLAUDE_MODEL,
              inputText: prompt,
              outputText: generatedText,
              durationMs: claudeDuration,
              status: "success"
            });

            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed: CLAUDE_MODEL,
                temperatureUsed: genParams.temperature,
                contentType: contentType || null
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          } else {
            console.warn("ğŸ¯ Text Generator: Claude returned no content");
          }
        } else {
          const errTxt = await claudeResponse.text();
          console.warn("ğŸ¯ Text Generator: Claude API error:", { status: claudeResponse.status, error: errTxt });
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: Claude threw error:", e);
      }
    }

    // â”€â”€ Fallback 1: OpenAI gpt-4.1-mini â”€â”€
    if (OPENAI_API_KEY && !generatedText) {
      try {
        console.log("ğŸ¯ Text Generator: FALLBACK 1 - OpenAI gpt-4.1-mini");
        const startOpenai = Date.now();
        const openaiResponse = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
          },
          body: JSON.stringify({
            model: 'gpt-4.1-mini',
            messages: [
              { role: "system", content: systemPrompt },
              { role: "user", content: prompt }
            ],
            temperature: genParams.temperature,
            max_tokens: genParams.max_tokens,
          }),
        });
        const openaiDuration = Date.now() - startOpenai;

        if (openaiResponse.ok) {
          const openaiResult = await openaiResponse.json();
          const content = openaiResult.choices?.[0]?.message?.content || "";
          if (content) {
            generatedText = sanitizeEmDashes(content);

            await logAIFromRequest(req, {
              functionName: "text-generator",
              provider: "openai",
              model: "gpt-4.1-mini",
              inputText: prompt,
              outputText: generatedText,
              durationMs: openaiDuration,
              status: "success"
            });

            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed: 'gpt-4.1-mini',
                temperatureUsed: genParams.temperature,
                contentType: contentType || null
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          }
        } else {
          const errTxt = await openaiResponse.text();
          console.warn("ğŸ¯ Text Generator: OpenAI fallback error:", errTxt);
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: OpenAI fallback threw:", e);
      }
    }

    // â”€â”€ Fallback 2: Gemini â”€â”€
    if (GEMINI_API_KEY && !generatedText) {
      try {
        console.log("ğŸ¯ Text Generator: FALLBACK 2 - Gemini gemini-2.5-flash-lite");
        const startGemini = Date.now();
        const result = await generateGemini(
          'gemini-2.5-flash-lite',
          [{ role: 'user', parts: [{ text: prompt }] }],
          systemPrompt,
          { temperature: genParams.temperature, maxOutputTokens: genParams.max_tokens },
          []
        );
        const geminiDuration = Date.now() - startGemini;
        const content = result?.candidates?.[0]?.content?.parts?.[0]?.text || "";
        if (content) {
          generatedText = sanitizeEmDashes(content);

          await logAIFromRequest(req, {
            functionName: "text-generator",
            provider: "gemini",
            model: "gemini-2.5-flash-lite",
            inputText: prompt,
            outputText: generatedText,
            durationMs: geminiDuration,
            status: "success"
          });

          return new Response(
            JSON.stringify({
              success: true,
              generatedText,
              mode,
              language,
              modelUsed: 'gemini-2.5-flash-lite',
              temperatureUsed: genParams.temperature,
              contentType: contentType || null
            }),
            { headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: Gemini fallback threw:", e);
      }
    }

    // â”€â”€ Fallback 3: DeepSeek â”€â”€
    if (DEEPSEEK_API_KEY && !generatedText) {
      try {
        console.log("ğŸ¯ Text Generator: FALLBACK 3 - DeepSeek");
        const startDs = Date.now();
        const dsResp = await fetch("https://api.deepseek.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${DEEPSEEK_API_KEY}`,
          },
          body: JSON.stringify({
            model: 'deepseek-chat',
            messages: [
              { role: "system", content: systemPrompt },
              { role: "user", content: prompt }
            ],
            temperature: genParams.temperature,
            max_tokens: genParams.max_tokens,
          }),
        });
        const dsDuration = Date.now() - startDs;
        console.log(`ğŸ¯ Text Generator: DeepSeek completed in ${dsDuration}ms`);
        if (dsResp.ok) {
          const result = await dsResp.json();
          const content = result.choices?.[0]?.message?.content || "";
          if (content) {
            generatedText = sanitizeEmDashes(content);
            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed: 'deepseek-chat',
                temperatureUsed: genParams.temperature,
                contentType: contentType || null
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          }
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: DeepSeek fallback threw:", e);
      }
    }

    return new Response(
      JSON.stringify({ 
        success: false,
        error: "No text generated from AI providers" 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, "Content-Type": "application/json" }
      }
    );
    
  } catch (error: unknown) {
    const err = error as Error;
    console.error("ğŸ¯ Text Generator: Unexpected error:", {
      name: err.name,
      message: err.message,
      stack: err.stack
    });
    
    await logAIFromRequest(req, {
      functionName: "text-generator",
      provider: "anthropic",
      model: CLAUDE_MODEL,
      status: "error",
      errorMessage: err.message
    });

    return new Response(
      JSON.stringify({ 
        success: false,
        error: `Text generation failed: ${err.message}` 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, "Content-Type": "application/json" }
      }
    );
  }
});

// ============================================================================
// Em-dash sanitation: guaranteed removal from all outputs
// ============================================================================
function sanitizeEmDashes(text: string): string {
  return text
    .replace(/\u2014/g, ', ')   // em-dash â†’ comma
    .replace(/\u2013/g, ', ')   // en-dash â†’ comma
    .replace(/ , /g, ', ')      // clean double spaces around comma
    .replace(/^, /gm, '');      // remove leading comma at line start
}

// ============================================================================
// System prompt builder: uses structured fields from frontend
// ============================================================================
interface StructuredFields {
  tone?: string;
  register?: string;
  languageVariant?: string;
  emojis?: string;
  contentType?: string;
}

function buildSystemPrompt(language: string, fields: StructuredFields): string {
  const isArabic = language === 'ar';
  const { tone, register, languageVariant, emojis, contentType } = fields;

  // â”€â”€ Base identity â”€â”€
  const basePrompt = isArabic
    ? 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØµÙˆØµ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙŠØ¯ ÙˆÙ…ØªØ³Ù‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….'
    : "You are an intelligent assistant specialized in generating high-quality text content. Your task is to create clear, helpful, and coherent content based on the user's request.";

  // â”€â”€ Hard formatting rules â”€â”€
  const formatRules = isArabic
    ? `
Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (Ø¥Ù„Ø²Ø§Ù…ÙŠØ©):
- Ø§ÙƒØªØ¨ Ù†ØµØ§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹
- ØªØ¬Ù†Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¬ÙˆÙ… (*) Ù„Ù„ØªÙ†Ø³ÙŠÙ‚
- Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø´Ø±Ø·Ø© Ø¥Ù… (â€”) Ø£Ùˆ Ø´Ø±Ø·Ø© Ø¥Ù† (â€“). Ù„Ø§ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ø£Ø¨Ø¯Ø§Ù‹ ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù.
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ ÙÙ‚Ø·`
    : `
Formatting rules (MANDATORY):
- Write clear and direct text
- Do not use asterisks (*) for formatting
- ABSOLUTELY NEVER use em-dashes (â€”) or en-dashes (â€“). Not even once. Use commas, periods, or semicolons instead.
- Focus only on text generation`;

  // â”€â”€ Structured constraints block (from dropdown selections) â”€â”€
  const constraints: string[] = [];

  // Content type
  if (contentType) {
    const ctName = contentType.replace(/_/g, ' ');
    constraints.push(isArabic ? `Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: ${ctName}` : `Content type: ${ctName}`);
  }

  // Tone
  if (tone) {
    if (tone === 'human') {
      constraints.push(isArabic
        ? 'Ø§Ù„Ù†Ø¨Ø±Ø©: Ø¨Ø´Ø±ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ. Ø§ÙƒØªØ¨ ÙˆÙƒØ£Ù†Ùƒ Ø¥Ù†Ø³Ø§Ù† Ø­Ù‚ÙŠÙ‚ÙŠ. Ù…Ù…Ù†ÙˆØ¹ Ø£ÙŠ Ø£Ø³Ù„ÙˆØ¨ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª ÙŠÙˆÙ…ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆØªØ¯ÙÙ‚ Ø·Ø¨ÙŠØ¹ÙŠ.'
        : 'Tone: Human (natural). Write like a real person. Never mention AI, models, or assistants. Use simple everyday wording and natural flow. Avoid the overly-polished AI vibe.');
    } else {
      constraints.push(isArabic ? `Ø§Ù„Ù†Ø¨Ø±Ø©: ${tone}` : `Tone: ${tone}`);
    }
  }

  // Register
  if (register) {
    const regLabels: Record<string, string> = {
      formal: isArabic ? 'Ø±Ø³Ù…ÙŠ' : 'Formal',
      neutral: isArabic ? 'Ù…Ø­Ø§ÙŠØ¯' : 'Neutral',
      casual: isArabic ? 'ØºÙŠØ± Ø±Ø³Ù…ÙŠ' : 'Casual',
      slang: isArabic ? 'Ø¹Ø§Ù…ÙŠ' : 'Slang',
      poetic: isArabic ? 'Ø´Ø¹Ø±ÙŠ / Ø£Ø¯Ø¨ÙŠ' : 'Poetic / Lyrical',
      gen_z: isArabic ? 'Ø£Ø³Ù„ÙˆØ¨ Ø¬ÙŠÙ„ Ø²Ø¯' : 'Gen Z style',
      business_formal: isArabic ? 'Ø±Ø³Ù…ÙŠ Ù„Ù„Ø£Ø¹Ù…Ø§Ù„' : 'Business Formal',
      executive_brief: isArabic ? 'Ù…ÙˆØ¬Ø² ØªÙ†ÙÙŠØ°ÙŠ' : 'Executive Brief',
    };
    constraints.push(isArabic ? `Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù„ØºÙˆÙŠ: ${regLabels[register] || register}` : `Register: ${regLabels[register] || register}`);
  }

  // Language variant
  if (languageVariant) {
    const v = languageVariant.toLowerCase();
    if (!isArabic) {
      if (v.includes('us')) constraints.push('Language variant: US English (color, center, check).');
      else if (v.includes('uk')) constraints.push('Language variant: UK English (colour, centre, cheque).');
      else if (v.includes('canadian')) constraints.push('Language variant: Canadian English (colour, centre). Prefer metric.');
      else if (v.includes('australian')) constraints.push('Language variant: Australian English. Prefer metric.');
    } else {
      if (v.includes('msa')) constraints.push('Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù„ØºÙˆÙŠ: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ MSA.');
      else if (v.includes('gulf')) constraints.push('Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù„ØºÙˆÙŠ: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ…ÙÙ‡ÙˆÙ….');
    }
  }

  // Emojis
  if (emojis) {
    const emojiRules: Record<string, string> = {
      none: isArabic ? 'Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ: Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ø¥ÙŠÙ…ÙˆØ¬ÙŠ.' : 'Emojis: Do NOT use any emojis.',
      light: isArabic ? 'Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ: Ø§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù‚Ù„ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (1-2 ÙÙ‚Ø·).' : 'Emojis: Use very few emojis (1-2 max).',
      rich: isArabic ? 'Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ: Ø§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ø¹ØªØ¯Ù„.' : 'Emojis: Use emojis moderately throughout.',
      extra: isArabic ? 'Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ: Ø§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨ÙƒØ«Ø§ÙØ©.' : 'Emojis: Use emojis heavily and expressively.',
    };
    if (emojiRules[emojis]) constraints.push(emojiRules[emojis]);
  }

  const constraintsBlock = constraints.length > 0
    ? (isArabic
      ? `\n\nØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§ØªØ¨Ø¹Ù‡Ø§ Ø¨Ø¯Ù‚Ø©):\n${constraints.map(c => `- ${c}`).join('\n')}`
      : `\n\nUser settings (follow strictly):\n${constraints.map(c => `- ${c}`).join('\n')}`)
    : '';

  return basePrompt + formatRules + constraintsBlock;
}
