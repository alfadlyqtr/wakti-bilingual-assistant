import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { generateGemini } from "../_shared/gemini.ts";
import { logAIFromRequest } from "../_shared/aiLogger.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
};

const DEEPSEEK_API_KEY = Deno.env.get("DEEPSEEK_API_KEY");
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const GEMINI_API_KEY = Deno.env.get("GEMINI_API_KEY") || Deno.env.get("GOOGLE_GENAI_API_KEY");

// Content type configurations
const contentConfig = {
  // Short form content types (emails, messages, etc.)
  email: { baseTokens: 1024, model: 'gpt-4o-mini', temperature: 0.7 },
  text_message: { baseTokens: 512, model: 'gpt-4o-mini', temperature: 0.7 },
  message: { baseTokens: 768, model: 'gpt-4o-mini', temperature: 0.7 },
  
  // Long form content types
  blog_post: { baseTokens: 2048, model: 'gpt-4o', temperature: 0.7 },
  story: { baseTokens: 3072, model: 'gpt-4o', temperature: 0.8 },
  press_release: { baseTokens: 1536, model: 'gpt-4o', temperature: 0.5 },
  cover_letter: { baseTokens: 1024, model: 'gpt-4o', temperature: 0.6 },
  research_brief: { baseTokens: 2048, model: 'gpt-4o', temperature: 0.4 },
  research_report: { baseTokens: 4096, model: 'gpt-4o', temperature: 0.4 },
  case_study: { baseTokens: 3072, model: 'gpt-4o', temperature: 0.6 },
  how_to_guide: { baseTokens: 2048, model: 'gpt-4o', temperature: 0.5 },
  policy_note: { baseTokens: 1536, model: 'gpt-4o', temperature: 0.4 },
  product_description: { baseTokens: 768, model: 'gpt-4o-mini', temperature: 0.7 },
  essay: { baseTokens: 3072, model: 'gpt-4o', temperature: 0.7 },
  proposal: { baseTokens: 2560, model: 'gpt-4o', temperature: 0.6 },
  official_letter: { baseTokens: 1024, model: 'gpt-4o', temperature: 0.5 },
  poem: { baseTokens: 1024, model: 'gpt-4o', temperature: 0.9 },
  
  // Default fallback
  default: { baseTokens: 1024, model: 'gpt-4o-mini', temperature: 0.7 }
};

// Length multipliers
const lengthMultipliers = {
  'very_short': 0.5,
  'short': 0.75,
  'medium': 1.0,
  'long': 1.5,
  'very_long': 2.0
};

// Tone adjustments
const toneAdjustments = {
  // Creative tones
  funny: { tempAdj: +0.2, tokenAdj: 1.0 },
  romantic: { tempAdj: +0.2, tokenAdj: 1.0 },
  humorous: { tempAdj: +0.3, tokenAdj: 1.0 },
  inspirational: { tempAdj: +0.1, tokenAdj: 1.1 },
  motivational: { tempAdj: +0.1, tokenAdj: 1.1 },
  
  // Professional tones
  professional: { tempAdj: -0.1, tokenAdj: 1.0 },
  formal: { tempAdj: -0.2, tokenAdj: 1.0 },
  serious: { tempAdj: -0.2, tokenAdj: 1.0 },
  authoritative: { tempAdj: -0.1, tokenAdj: 1.0 },
  
  // Neutral tones
  neutral: { tempAdj: 0, tokenAdj: 1.0 },
  friendly: { tempAdj: +0.1, tokenAdj: 1.0 },
  empathetic: { tempAdj: +0.1, tokenAdj: 1.0 },
  
  // Default fallback
  default: { tempAdj: 0, tokenAdj: 1.0 }
};

// Register adjustments: influence temperature and tokens based on register (formality/style)
const registerAdjustments = {
  auto:       { tempAdj: 0.0,  tokenAdj: 1.0 },
  formal:     { tempAdj: -0.10, tokenAdj: 1.0 },
  neutral:    { tempAdj: 0.0,  tokenAdj: 1.0 },
  casual:     { tempAdj: +0.05, tokenAdj: 1.0 },
  slang:      { tempAdj: +0.10, tokenAdj: 0.90 },
  poetic:     { tempAdj: +0.05, tokenAdj: 1.10 },
  gen_z:      { tempAdj: +0.10, tokenAdj: 0.90 },
  business_formal: { tempAdj: -0.10, tokenAdj: 1.0 },
  executive_brief: { tempAdj: -0.10, tokenAdj: 0.85 },
} as const;

// Get generation parameters based on content type, tone, length, and register
function getGenerationParams(contentType: string, tone: string, length: string, register?: string) {
  const config = contentConfig[contentType as keyof typeof contentConfig] || contentConfig.default;
  const lengthMult = lengthMultipliers[length as keyof typeof lengthMultipliers] || 1.0;
  const toneAdj = toneAdjustments[tone as keyof typeof toneAdjustments] || toneAdjustments.default;
  const regAdj = registerAdjustments[(register as keyof typeof registerAdjustments) || 'auto'] || registerAdjustments.auto;
  
  // Calculate final values with bounds
  const finalTemp = Math.min(1.0, Math.max(0.1, config.temperature + toneAdj.tempAdj + regAdj.tempAdj));
  const finalTokens = Math.max(256, Math.min(4096, Math.floor(config.baseTokens * lengthMult * toneAdj.tokenAdj * regAdj.tokenAdj)));
  
  return {
    model: config.model,
    temperature: finalTemp,
    max_tokens: finalTokens
  };
}

serve(async (req) => {
  // Handle CORS
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log("ğŸ¯ Text Generator: Function called successfully - Processing request");
    console.log("ğŸ¯ Text Generator: Request method:", req.method);
    console.log("ğŸ¯ Text Generator: Request headers:", Object.fromEntries(req.headers.entries()));
    
    if (!OPENAI_API_KEY && !DEEPSEEK_API_KEY) {
      console.error("ğŸš¨ Text Generator: No AI provider keys found in environment");
      return new Response(
        JSON.stringify({ 
          success: false,
          error: "No AI provider configured. Please add OPENAI_API_KEY or DEEPSEEK_API_KEY to Supabase Edge Function Secrets." 
        }),
        { 
          status: 500, 
          headers: { ...corsHeaders, "Content-Type": "application/json" }
        }
      );
    }

    let requestBody;
    try {
      requestBody = await req.json();
      console.log("ğŸ¯ Text Generator: Request body parsed successfully");
    } catch (parseError) {
      console.error("ğŸ¯ Text Generator: Failed to parse request body:", parseError);
      requestBody = {};
    }

    const { prompt, mode, language, languageVariant, messageAnalysis, modelPreference, temperature, contentType, length, replyLength, tone, register, image, extractTarget } = requestBody;

    console.log("ğŸ¯ Request details:", { 
      promptLength: prompt?.length || 0, 
      mode, 
      language,
      hasMessageAnalysis: !!messageAnalysis,
      contentType,
      length,
      replyLength,
      tone,
      hasImage: !!image,
      extractTarget
    });

    // ============================================
    // MODE: extract - Extract text from screenshot
    // ============================================
    if (mode === 'extract' && image) {
      console.log("ğŸ¯ Text Generator: EXTRACT MODE - Processing screenshot");
      
      if (!OPENAI_API_KEY) {
        return new Response(
          JSON.stringify({ 
            success: false,
            error: "OpenAI API key required for image extraction" 
          }),
          { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }

      try {
        // Prepare the image for OpenAI Vision API
        let imageUrl = image;
        if (!image.startsWith('http') && !image.startsWith('data:')) {
          imageUrl = `data:image/jpeg;base64,${image}`;
        }

        // Use structured extraction prompt to detect form fields
        const structuredPrompt = language === 'ar'
          ? `Ø§Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆØ­Ø¯Ø¯ Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±Ø§Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø· (Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆÙ…ØµØ¯Ø±Ù‡)ØŒ Ø«Ù… Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†.

Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø· ÙˆØ¨Ù†ÙØ³ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©. Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§:
- Ù„Ø§ ØªÙØ±Ø¬Ø¹ Ø£ÙŠ Ù†Øµ Ø®Ø§Ø±Ø¬ JSON.
- Ø§Ø¬Ø¹Ù„ rawText Ø´Ø§Ù…Ù„Ø§Ù‹ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù† (Ù„Ø§ ØªØ®ØªØµØ±).
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„Ù‹Ø§ØŒ Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Ù…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø±Ø¤ÙŠØªÙ‡ Ø¨ÙˆØ¶ÙˆØ­.

{
  "isScreenshot": true/false,
  "sourceType": "email" | "whatsapp" | "sms" | "imessage" | "support_portal" | "web_page" | "form" | "handwritten" | "photo" | "other",
  "deviceType": "phone" | "tablet" | "desktop" | "unknown",
  "isForm": true/false,
  "formType": "support_ticket" | "contact_form" | "email" | "message" | "other",
  "fields": {
    "subject": "Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¥Ù† ÙˆØ¬Ø¯",
    "category": "Ø§Ù„ÙØ¦Ø© Ø£Ùˆ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "service_affected": "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "severity": "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„Ø®Ø·ÙˆØ±Ø© Ø¥Ù† ÙˆØ¬Ø¯",
    "message": "Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ / ÙˆØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©",
    "sender": "Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø³Ù„ Ø¥Ù† ÙˆØ¬Ø¯",
    "recipient": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ„Ù… Ø¥Ù† ÙˆØ¬Ø¯"
  },
  "rawText": "ÙƒÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¦ÙŠ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©"
}

Ø£Ø¹Ø¯ JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ.`
          : `Look at this image carefully and first identify what it is (type + source), then extract as much text as possible.

Return ONLY valid JSON using this exact schema:
- No extra text outside JSON.
- rawText should include as much visible text as possible (do NOT summarize).
- If the text is long, extract everything you can clearly read.

{
  "isScreenshot": true/false,
  "sourceType": "email" | "whatsapp" | "sms" | "imessage" | "support_portal" | "web_page" | "form" | "handwritten" | "photo" | "other",
  "deviceType": "phone" | "tablet" | "desktop" | "unknown",
  "isForm": true/false,
  "formType": "support_ticket" | "contact_form" | "email" | "message" | "other",
  "fields": {
    "subject": "the subject/title if present",
    "category": "category/issue type if present",
    "service_affected": "which service is affected if present",
    "severity": "priority or severity if present",
    "message": "the main message body / issue description",
    "sender": "sender name if present",
    "recipient": "recipient name if present"
  },
  "rawText": "all visible text in the image"
}

Return ONLY the JSON, no additional text.`;

        console.log("ğŸ¯ Text Generator: Calling OpenAI Vision for structured extraction");
        const startVision = Date.now();
        
        const visionResponse = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
          },
          body: JSON.stringify({
            model: "gpt-4o",
            messages: [
              {
                role: "user",
                content: [
                  { type: "text", text: structuredPrompt },
                  { type: "image_url", image_url: { url: imageUrl, detail: "high" } }
                ]
              }
            ],
            response_format: { type: "json_object" },
            max_tokens: 4000,
            temperature: 0.1,
          }),
        });

        const visionDuration = Date.now() - startVision;
        console.log(`ğŸ¯ Text Generator: Vision extraction completed in ${visionDuration}ms, status: ${visionResponse.status}`);

        if (!visionResponse.ok) {
          const errText = await visionResponse.text();
          console.error("ğŸ¯ Text Generator: Vision API error:", errText);
          return new Response(
            JSON.stringify({ success: false, error: "Failed to extract text from image" }),
            { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        }

        const visionResult = await visionResponse.json();
        const rawContent = visionResult.choices?.[0]?.message?.content || "";

        if (!rawContent.trim()) {
          return new Response(
            JSON.stringify({ success: false, error: "No text found in image" }),
            { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        }

        // Try to parse as JSON, fallback to raw text
        let extractedData: {
          isScreenshot?: boolean;
          sourceType?: string;
          deviceType?: string;
          isForm?: boolean;
          formType?: string;
          fields?: Record<string, string>;
          rawText?: string;
        } = {};
        let extractedText = rawContent;

        try {
          // Clean up potential markdown code blocks
          let jsonStr = rawContent.trim();
          if (jsonStr.startsWith('```json')) jsonStr = jsonStr.slice(7);
          if (jsonStr.startsWith('```')) jsonStr = jsonStr.slice(3);
          if (jsonStr.endsWith('```')) jsonStr = jsonStr.slice(0, -3);
          jsonStr = jsonStr.trim();
          
          extractedData = JSON.parse(jsonStr);
          extractedText = extractedData.rawText || rawContent;
          console.log("ğŸ¯ Text Generator: Successfully parsed structured form data:", {
            isForm: extractedData.isForm,
            formType: extractedData.formType,
            fieldsCount: extractedData.fields ? Object.keys(extractedData.fields).length : 0
          });
        } catch (_parseErr) {
          console.log("ğŸ¯ Text Generator: Could not parse as JSON, using raw text");
          extractedData = { isForm: false, rawText: rawContent };
        }

        console.log("ğŸ¯ Text Generator: Successfully extracted, length:", extractedText.length);

        // Log successful extraction
        await logAIFromRequest(req, {
          functionName: "text-generator",
          provider: "openai",
          model: "gpt-4o",
          inputText: "[image extraction]",
          outputText: extractedText,
          durationMs: visionDuration,
          status: "success"
        });

        return new Response(
          JSON.stringify({
            success: true,
            extractedText,
            extractedForm: extractedData.isForm ? {
              formType: extractedData.formType || 'other',
              fields: extractedData.fields || {}
            } : null,
            extractedMeta: {
              isScreenshot: extractedData.isScreenshot ?? true,
              sourceType: extractedData.sourceType || 'other',
              deviceType: extractedData.deviceType || 'unknown',
            },
            mode: 'extract',
            extractTarget,
            modelUsed: 'gpt-4o'
          }),
          { headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );

      } catch (e: unknown) {
        const err = e as Error;
        console.error("ğŸ¯ Text Generator: Extraction error:", err.message);
        return new Response(
          JSON.stringify({ success: false, error: `Extraction failed: ${err.message}` }),
          { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
    }

    // ============================================
    // MODE: compose/reply - Normal text generation
    // ============================================
    if (!prompt) {
      console.error("ğŸ¯ Text Generator: Missing prompt in request");
      return new Response(
        JSON.stringify({ 
          success: false,
          error: "Prompt is required" 
        }),
        { 
          status: 400, 
          headers: { ...corsHeaders, "Content-Type": "application/json" }
        }
      );
    }

    console.log("ğŸ¯ Text Generator: Calling AI provider for text generation");
    console.log("ğŸ¯ Mode:", mode);
    console.log("ğŸ¯ Language:", language);
    console.log("ğŸ¯ Prompt length:", prompt.length);
    console.log("ğŸ¯ Requested modelPreference:", modelPreference);
    console.log("ğŸ¯ Requested temperature:", temperature);

    const systemPrompt = getSystemPrompt(language, languageVariant);
    const genParams = getGenerationParams(contentType, tone, length || 'medium', register);
    console.log("ğŸ¯ Generation parameters:", genParams);

    let generatedText: string | undefined;

    // Try Gemini first if available
    if (GEMINI_API_KEY) {
      try {
        console.log("ğŸ¯ Text Generator: Attempting Gemini (gemini-2.5-flash-lite)");
        const startGemini = Date.now();
        const result = await generateGemini(
          'gemini-2.5-flash-lite',
          [{ role: 'user', parts: [{ text: prompt }] }],
          systemPrompt,
          { temperature: genParams.temperature, maxOutputTokens: genParams.max_tokens },
          []
        );
        const geminiDuration = Date.now() - startGemini;
        console.log(`ğŸ¯ Text Generator: Gemini request completed in ${geminiDuration}ms`);

        const content = result?.candidates?.[0]?.content?.parts?.[0]?.text || "";
        if (content) {
          generatedText = content;
          console.log("ğŸ¯ Text Generator: Successfully generated text, length:", generatedText?.length || 0, "model: gemini-2.5-flash-lite");

          // Log successful AI usage
          await logAIFromRequest(req, {
            functionName: "text-generator",
            provider: "gemini",
            model: "gemini-2.5-flash-lite",
            inputText: prompt,
            outputText: generatedText,
            durationMs: geminiDuration,
            status: "success"
          });

          return new Response(
            JSON.stringify({
              success: true,
              generatedText,
              mode,
              language,
              modelUsed: 'gemini-2.5-flash-lite',
              temperatureUsed: genParams.temperature,
              contentType: contentType || null
            }),
            { headers: { ...corsHeaders, "Content-Type": "application/json" } }
          );
        } else {
          console.warn("ğŸ¯ Text Generator: Gemini returned no content");
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: Gemini request threw error:", e);
      }
    }

    // Fallback to OpenAI if Gemini failed or unavailable
    if (OPENAI_API_KEY && !generatedText) {
      try {
        console.log("ğŸ¯ Text Generator: Attempting OpenAI", genParams.model);
        const startOpenai = Date.now();
        const openaiResponse = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`,
          },
          body: JSON.stringify({
            model: genParams.model,
            messages: [
              { role: "system", content: systemPrompt },
              { role: "user", content: prompt }
            ],
            temperature: genParams.temperature,
            max_tokens: genParams.max_tokens,
          }),
        });
        const openaiDuration = Date.now() - startOpenai;
        console.log(`ğŸ¯ Text Generator: OpenAI request completed in ${openaiDuration}ms with status ${openaiResponse.status}`);

        if (openaiResponse.ok) {
          const openaiResult = await openaiResponse.json();
          const content = openaiResult.choices?.[0]?.message?.content || "";
          if (content) {
            generatedText = content;
            const modelUsed = genParams.model;
            console.log("ğŸ¯ Text Generator: Successfully generated text, length:", generatedText?.length || 0, "model:", modelUsed);

            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed,
                temperatureUsed: genParams.temperature,
                contentType: contentType || null
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          } else {
            console.warn("ğŸ¯ Text Generator: OpenAI returned no content");
          }
        } else {
          const errTxt = await openaiResponse.text();
          console.warn("ğŸ¯ Text Generator: OpenAI API error:", { status: openaiResponse.status, statusText: openaiResponse.statusText, error: errTxt });
        }
      } catch (e) {
        console.warn("ğŸ¯ Text Generator: OpenAI request threw error:", e);
      }
    }

    // Fallback to DeepSeek if needed and available
    if (!OPENAI_API_KEY || (!generatedText && DEEPSEEK_API_KEY)) {
      try {
        console.log("ğŸ¯ Text Generator: Falling back to DeepSeek (deepseek-chat)");
        const startDeepseek = Date.now();
        const deepseekResponse = await fetch("https://api.deepseek.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${DEEPSEEK_API_KEY}`,
          },
          body: JSON.stringify({
            model: genParams.model,
            messages: [
              { role: "system", content: systemPrompt },
              { role: "user", content: prompt }
            ],
            temperature: genParams.temperature,
            max_tokens: genParams.max_tokens,
          }),
        });
        const deepseekDuration = Date.now() - startDeepseek;
        console.log(`ğŸ¯ Text Generator: DeepSeek request completed in ${deepseekDuration}ms with status ${deepseekResponse.status}`);

        if (deepseekResponse.ok) {
          const result = await deepseekResponse.json();
          const content = result.choices?.[0]?.message?.content || "";
          if (content) {
            generatedText = content;
            const modelUsed = genParams.model;
            console.log("ğŸ¯ Text Generator: Successfully generated text, length:", generatedText?.length || 0, "model:", modelUsed);

            return new Response(
              JSON.stringify({
                success: true,
                generatedText,
                mode,
                language,
                modelUsed,
                temperatureUsed: genParams.temperature,
                contentType: contentType || null
              }),
              { headers: { ...corsHeaders, "Content-Type": "application/json" } }
            );
          } else {
            console.error("ğŸ¯ Text Generator: No text generated from DeepSeek API", JSON.stringify(result));
          }
        } else {
          const errorText = await deepseekResponse.text();
          console.error("ğŸ¯ Text Generator: DeepSeek API error:", { status: deepseekResponse.status, statusText: deepseekResponse.statusText, error: errorText });
        }
      } catch (e) {
        console.error("ğŸ¯ Text Generator: DeepSeek request threw error:", e);
      }
    }

    return new Response(
      JSON.stringify({ 
        success: false,
        error: "No text generated from AI providers" 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, "Content-Type": "application/json" }
      }
    );
    
  } catch (error: unknown) {
    const err = error as Error;
    console.error("ğŸ¯ Text Generator: Unexpected error:", {
      name: err.name,
      message: err.message,
      stack: err.stack
    });
    
    // Log failed AI usage
    await logAIFromRequest(req, {
      functionName: "text-generator",
      provider: "gemini",
      model: "gemini-2.5-flash-lite",
      status: "error",
      errorMessage: err.message
    });

    return new Response(
      JSON.stringify({ 
        success: false,
        error: `Text generation failed: ${err.message}` 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, "Content-Type": "application/json" }
      }
    );
  }
});

// System prompt for text generation with language variant enforcement
function getSystemPrompt(language: string, languageVariant?: string): string {
  const isArabic = language === 'ar';

  // Normalize variant for robust matching (e.g., "Canadian English", "en-CA", "CA")
  const v = (languageVariant || '').toString().trim().toLowerCase();

  let variantLine = '';
  if (!isArabic) {
    if (v.includes('canadian') || v.includes('en-ca') || v === 'ca' || v.includes('canada')) {
      variantLine = 'Use Canadian English spelling and phrasing (e.g., colour, centre, cheque, licence, defence). Prefer metric units.';
    } else if (v.includes('us') || v.includes('en-us') || v.includes('american')) {
      variantLine = 'Use US English spelling and phrasing (e.g., color, center, check, license, defense).';
    } else if (v.includes('uk') || v.includes('en-gb') || v.includes('british')) {
      variantLine = 'Use UK English spelling and phrasing (e.g., colour, centre, cheque, licence, defence).';
    } else if (v.includes('aus') || v.includes('au') || v.includes('australian') || v.includes('en-au')) {
      variantLine = 'Use Australian English spelling and phrasing. Prefer metric units.';
    }
  } else {
    if (v.includes('msa') || v.includes('modern standard') || v.includes('ÙØµØ­Ù‰') || v.includes('fusha')) {
      variantLine = 'Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ MSA.';
    } else if (v.includes('gulf') || v.includes('khaleeji') || v.includes('Ø§Ù„Ø®Ù„ÙŠØ¬') || v.includes('Ø®Ù„ÙŠØ¬')) {
      variantLine = 'Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ…ÙÙ‡ÙˆÙ….';
    }
  }

  const basePrompt = isArabic
    ? 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØµÙˆØµ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙŠØ¯ ÙˆÙ…ØªØ³Ù‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….'
    : "You are an intelligent assistant specialized in generating high-quality text content. Your task is to create clear, helpful, and coherent content based on the user's request.";

  const guidelines = isArabic
    ? `
Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ÙŠØ©:
- Ø§ÙƒØªØ¨ Ù†ØµØ§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹
- ØªØ¬Ù†Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¬ÙˆÙ… (*) Ù„Ù„ØªÙ†Ø³ÙŠÙ‚
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£Ø¨Ø¯Ø§Ù‹ Ø´Ø±Ø·Ø© Ø¥Ù… (â€”) ÙˆÙ„Ø§ Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© (-)
- Ø§ØªØ¨Ø¹ Ø¨Ø¯Ù‚Ø© Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ø§Ù„Ù†Ø¨Ø±Ø©ØŒ ÙˆØ§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ³Ø§Ù‚ ÙÙŠ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨
- Ù‚Ø¯Ù… Ù…Ø­ØªÙˆÙ‰ Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆØ°Ø§ ØµÙ„Ø©
- Ù„Ø§ ØªØ¶Ø¹ Ø§ÙØªØ±Ø§Ø¶Ø§Øª ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠØ©
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ ÙÙ‚Ø·`
    : `
Guidelines:
- Write clear and direct text
- Do not use asterisks (*) for formatting
- NEVER use em-dashes (â€”) and hyphens (-)
- Strictly follow the requested Content Type, Tone, and Length
- Maintain consistency in style
- Provide helpful and relevant content
- Do not make unnecessary assumptions
- Focus only on text generation`;

  const variantBlock = variantLine
    ? (isArabic ? `\nØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù„ØºÙˆÙŠ: ${variantLine}` : `\nLanguage variant instruction: ${variantLine}`)
    : '';

  return basePrompt + guidelines + variantBlock;
}
